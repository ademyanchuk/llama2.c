{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False, threshold=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1b1eb4e03d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Transformer, ModelArgs\n",
    "from export import version1_export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = ModelArgs(dim=64, n_layers=2, n_heads=2, vocab_size=128, multiple_of=64, max_seq_len=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (tok_embeddings): Embedding(128, 64)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (layers): ModuleList(\n",
       "    (0-1): 2 x TransformerBlock(\n",
       "      (attention): Attention(\n",
       "        (wq): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (wk): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (wv): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (wo): Linear(in_features=64, out_features=64, bias=False)\n",
       "        (attn_dropout): Dropout(p=0.0, inplace=False)\n",
       "        (resid_dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (feed_forward): FeedForward(\n",
       "        (w1): Linear(in_features=64, out_features=192, bias=False)\n",
       "        (w2): Linear(in_features=192, out_features=64, bias=False)\n",
       "        (w3): Linear(in_features=64, out_features=192, bias=False)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (attention_norm): RMSNorm()\n",
       "      (ffn_norm): RMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): RMSNorm()\n",
       "  (output): Linear(in_features=64, out_features=128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trns = Transformer(args)\n",
    "trns.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote test_qmodel.bin\n"
     ]
    }
   ],
   "source": [
    "# version1_export(trns, \"test_qmodel.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import precompute_freqs_cis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs_cos, freqs_sin = precompute_freqs_cis(args.dim // args.n_heads, args.max_seq_len, theta=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_input = torch.randn((2, seq_len, args.dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_input.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1953,  1.3208,  0.2495, -0.1673, -0.0591,  0.3616,  1.3410, -0.8957,\n",
       "         0.6161,  1.2228, -0.1955, -0.7414, -0.3080, -2.1912,  0.2576,  0.0792,\n",
       "        -1.3583, -0.1788,  1.2726,  0.6850, -0.6112,  1.0188, -0.5511,  1.8887,\n",
       "         1.3301,  1.0066,  0.4750, -1.4066, -0.8390, -0.3888, -0.2326,  1.0632,\n",
       "         0.0810, -2.1969,  0.4605, -1.4893, -2.9533,  1.4599,  2.3899, -0.3932,\n",
       "        -0.9568, -1.1449,  1.4483,  1.2406,  0.1914,  1.4117, -0.4767, -1.0781,\n",
       "        -0.9110,  1.2804,  0.3797,  0.9956, -1.5105, -0.7912,  1.3679, -0.5590,\n",
       "        -2.1662, -0.9770,  0.4323,  0.1489, -0.7385,  0.7942, -0.1410,  0.1094,\n",
       "        -0.0592, -1.2568, -0.1238, -2.5755, -0.8053, -1.3994,  0.4603,  0.8535,\n",
       "        -0.4498, -0.1781,  2.5215,  1.4743,  1.1519, -0.5641,  1.2015, -0.1887,\n",
       "         0.1653,  0.5446,  0.3146, -0.8870,  0.1913,  0.3718,  2.1777, -0.2279,\n",
       "        -0.9992, -1.7526,  0.4812,  0.0654,  0.0687,  1.2828, -0.5617,  0.0165,\n",
       "        -0.3389,  1.7562, -0.1553, -0.6532,  1.1198, -1.0308,  0.7332, -1.4438,\n",
       "        -0.1191,  0.1892, -1.7991,  0.5532, -0.5386, -0.0907,  1.4513,  0.9652,\n",
       "         2.0642,  0.1129,  0.2854,  0.1174, -1.4354, -0.1921, -0.2055, -0.8980,\n",
       "        -0.2869, -1.2090, -0.7769,  2.1963, -0.6920, -0.3065,  0.4637,  0.9324,\n",
       "        -0.0454, -1.1395,  1.1676, -1.0956, -1.4061,  0.3949,  1.7383,  0.0465,\n",
       "        -0.6257, -0.9177,  0.9600,  0.5548,  0.4594, -1.8951,  1.2409,  1.2922,\n",
       "        -0.8103,  2.0628, -1.3318,  1.2248,  0.9976, -0.0592,  0.5671,  0.2027,\n",
       "        -0.8797,  1.0151, -0.4292,  1.5308, -0.8948,  0.5809,  1.2779, -0.4835,\n",
       "        -0.3430,  1.0017,  0.0746,  2.9222, -0.3209, -2.2711, -0.2070,  0.4909,\n",
       "        -0.8745, -0.5031, -0.8557,  1.1927, -0.0120,  0.1751,  0.3558,  0.2868,\n",
       "         1.9694,  0.6073,  1.3333, -0.6127, -0.5755,  0.9575,  0.3363,  0.6825,\n",
       "        -1.2034, -0.2774, -0.5739,  1.3363, -1.7788, -0.3510,  1.4043,  2.6730,\n",
       "        -0.9076,  1.7382,  0.6019, -0.8866,  1.8655,  0.6915, -0.2155,  0.2384,\n",
       "        -1.2490, -0.3585, -0.7778, -0.8391,  0.4438, -0.5722,  0.8213, -1.3820,\n",
       "         1.3949,  0.1258,  0.6318,  0.7959,  0.0350, -0.4477,  1.8725, -1.2759,\n",
       "         0.6101, -1.8265, -0.3220, -0.2393, -0.2857, -1.2471,  2.0568,  0.0477,\n",
       "         0.2280, -0.6566,  0.7685,  0.5570,  0.3304, -0.5896, -0.2417, -1.1037,\n",
       "         1.1491,  0.3892,  1.1987, -1.8139, -0.4665,  0.4205, -1.2450, -0.1874,\n",
       "        -0.0625, -0.6863, -1.3980, -0.3396, -2.3933,  0.9353,  0.2394,  1.0501,\n",
       "         0.4706,  0.7173,  0.6932,  0.8610, -1.4228,  0.5227,  1.2203, -0.9596,\n",
       "         0.8399, -0.7494,  0.3700,  1.0649, -1.1766, -0.2136,  0.2073,  0.7881,\n",
       "         0.7528, -0.7143,  1.7323,  0.0207,  0.8833, -0.3503,  0.2890, -0.5052,\n",
       "         0.8249, -0.6354, -0.6237, -1.3503, -2.3354,  0.2957,  0.0475, -0.7995,\n",
       "        -1.0910, -0.2936,  0.9999, -1.0496, -1.3809, -0.6867,  0.7613, -1.5930,\n",
       "        -0.9528, -0.3339, -0.5963,  0.9015, -2.8716,  0.4748, -0.4446, -0.1752,\n",
       "         0.8383, -0.7566,  0.9605, -0.2822,  1.5081, -0.4385, -1.1229,  1.9875,\n",
       "         0.7019, -1.0667, -0.6145,  0.3115, -0.7919,  1.9569,  1.0253, -1.2840,\n",
       "        -0.0799, -1.6975,  1.5130,  0.1756, -1.1530, -0.1424, -0.1174,  1.3437,\n",
       "        -1.1433,  1.9139,  0.6524, -0.2460, -1.4980, -1.0622,  0.2421, -0.7968,\n",
       "        -0.1541, -0.3070,  0.5965, -0.6440, -0.7704,  0.0416,  1.1825, -0.5789,\n",
       "         0.5838,  2.3634, -0.4392,  0.7809, -0.7645,  0.1930, -0.2005, -0.8774,\n",
       "         0.0347, -0.1357,  1.0669,  0.1096,  1.2606,  0.2208, -0.7536, -0.5686,\n",
       "         1.1066, -1.6683,  0.9743, -0.2671,  1.0369, -0.9741, -0.5842,  0.1931,\n",
       "         0.7820, -0.4721, -0.9153,  0.4608,  0.6730, -0.3882,  0.3991, -0.3349,\n",
       "        -0.5057,  1.6616,  0.4073,  0.5080,  0.5863,  1.5346, -0.0966, -0.1089,\n",
       "        -1.0457, -1.7705, -0.8058,  1.6763, -0.4483, -0.0987, -1.5766,  0.2378,\n",
       "         1.2158,  0.2150, -0.7393, -1.0363,  0.4983, -1.1159,  0.1459, -0.6915,\n",
       "         0.6457, -0.0096,  1.5469,  1.6492, -0.5489, -1.5648, -0.1534, -1.5221,\n",
       "         1.1391, -0.0069,  0.5072,  0.5021, -0.7751,  0.0743,  0.0571,  0.1331,\n",
       "        -0.5631, -0.7800,  2.4179,  0.2946,  0.2490,  0.6455, -0.3038,  0.2338,\n",
       "         0.0229, -1.6619,  0.1834, -0.5939, -1.1509,  0.2156, -0.9903,  0.0766,\n",
       "         0.9693,  0.2694, -0.5370, -1.6298, -0.0868,  0.3347, -0.9241, -0.2812,\n",
       "         0.4042, -1.8786, -0.4547,  0.3153,  0.2203,  0.9424, -1.7609,  0.3489,\n",
       "         1.6077, -1.1236, -1.0121,  0.6232,  0.7292, -0.7591, -0.2043,  0.6250,\n",
       "         0.4268, -0.5841, -0.2946,  0.1147,  0.9012,  0.9583, -1.5040, -0.1264,\n",
       "         1.1511, -1.3689,  0.5645,  0.8932,  0.2642,  0.7885, -0.7912,  0.5675,\n",
       "         1.2805, -0.6204, -0.5846,  0.8035,  1.0760, -0.1776, -1.0264,  0.6843,\n",
       "         2.2635,  1.9114, -1.6167, -0.3707,  0.8183,  0.0979, -1.1274, -0.9781,\n",
       "         1.0171, -1.3377, -1.0062, -1.0650, -1.4433,  0.3444,  2.0505, -1.0859,\n",
       "         0.5379, -0.8437, -0.1673,  0.0769, -0.2621, -0.8928, -0.8537, -1.6520,\n",
       "        -1.4754,  0.8571, -0.5871,  0.4556,  0.0758, -1.5502,  0.4495, -0.2114,\n",
       "         1.9654,  1.8560,  0.7546,  0.3774, -1.2650,  0.6540, -1.0323,  0.7859])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_input.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_out = trns.layers[0].attention.forward(attn_input, freqs_cos[:seq_len], freqs_sin[:seq_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 64])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0.0075,     -0.0026,      0.0036,      0.0030,     -0.0054,\n",
       "             0.0292,     -0.0237,      0.0184,     -0.0082,     -0.0130,\n",
       "            -0.0035,      0.0040,      0.0218,      0.0066,      0.0012,\n",
       "            -0.0013,      0.0048,      0.0216,      0.0087,      0.0048,\n",
       "             0.0000,      0.0175,      0.0174,     -0.0108,      0.0115,\n",
       "             0.0020,      0.0106,     -0.0113,     -0.0047,      0.0158,\n",
       "             0.0040,      0.0123,     -0.0040,     -0.0076,      0.0059,\n",
       "            -0.0118,     -0.0213,     -0.0106,      0.0068,     -0.0006,\n",
       "            -0.0020,     -0.0106,      0.0091,     -0.0211,      0.0162,\n",
       "            -0.0130,     -0.0020,     -0.0058,     -0.0189,      0.0125,\n",
       "             0.0026,      0.0141,     -0.0200,     -0.0145,     -0.0071,\n",
       "             0.0127,     -0.0006,     -0.0048,      0.0071,     -0.0078,\n",
       "             0.0007,     -0.0046,     -0.0124,     -0.0114,     -0.0116,\n",
       "            -0.0066,      0.0020,     -0.0021,     -0.0165,      0.0219,\n",
       "            -0.0084,      0.0036,      0.0040,     -0.0103,     -0.0072,\n",
       "             0.0021,      0.0117,      0.0035,     -0.0080,     -0.0018,\n",
       "             0.0078,      0.0051,     -0.0054,      0.0015,     -0.0015,\n",
       "            -0.0027,      0.0051,     -0.0044,     -0.0014,      0.0139,\n",
       "             0.0069,     -0.0124,     -0.0112,      0.0087,      0.0078,\n",
       "             0.0092,     -0.0033,     -0.0027,     -0.0060,     -0.0076,\n",
       "            -0.0093,     -0.0069,      0.0105,      0.0017,      0.0070,\n",
       "             0.0012,      0.0005,     -0.0056,     -0.0016,     -0.0109,\n",
       "            -0.0008,      0.0050,     -0.0003,      0.0036,     -0.0046,\n",
       "             0.0050,     -0.0090,      0.0049,     -0.0011,      0.0077,\n",
       "            -0.0057,     -0.0055,      0.0064,     -0.0069,     -0.0002,\n",
       "            -0.0030,     -0.0125,     -0.0151,     -0.0133,     -0.0013,\n",
       "             0.0024,      0.0041,     -0.0192,      0.0185,     -0.0050,\n",
       "            -0.0063,     -0.0008,     -0.0022,     -0.0032,     -0.0070,\n",
       "             0.0079,      0.0037,     -0.0055,     -0.0038,     -0.0006,\n",
       "            -0.0035,      0.0007,     -0.0037,      0.0104,     -0.0037,\n",
       "             0.0085,     -0.0073,     -0.0045,      0.0059,      0.0054,\n",
       "            -0.0109,     -0.0112,      0.0043,      0.0065,     -0.0011,\n",
       "            -0.0077,     -0.0046,     -0.0152,     -0.0018,     -0.0022,\n",
       "            -0.0024,      0.0075,      0.0068,      0.0040,      0.0029,\n",
       "            -0.0026,     -0.0037,     -0.0018,     -0.0126,     -0.0036,\n",
       "             0.0122,     -0.0006,     -0.0019,     -0.0056,      0.0015,\n",
       "            -0.0088,      0.0016,     -0.0031,      0.0143,     -0.0035,\n",
       "            -0.0011,      0.0023,     -0.0078,     -0.0055,      0.0077,\n",
       "            -0.0145,     -0.0132,     -0.0109,      0.0030,      0.0064,\n",
       "            -0.0013,     -0.0188,      0.0115,     -0.0029,     -0.0091,\n",
       "             0.0031,     -0.0013,     -0.0041,     -0.0067,      0.0118,\n",
       "            -0.0019,     -0.0074,     -0.0026,      0.0014,     -0.0069,\n",
       "             0.0049,     -0.0036,      0.0116,     -0.0041,      0.0000,\n",
       "            -0.0124,     -0.0049,      0.0080,     -0.0035,     -0.0051,\n",
       "            -0.0045,      0.0046,      0.0056,     -0.0075,     -0.0038,\n",
       "            -0.0005,     -0.0133,     -0.0007,     -0.0015,     -0.0042,\n",
       "             0.0068,      0.0019,      0.0074,      0.0046,     -0.0011,\n",
       "            -0.0009,      0.0004,     -0.0056,     -0.0021,      0.0105,\n",
       "             0.0055,      0.0009,     -0.0052,     -0.0012,     -0.0044,\n",
       "             0.0024,     -0.0000,      0.0088,     -0.0067,      0.0021,\n",
       "             0.0096,     -0.0109,     -0.0026,     -0.0003,     -0.0092,\n",
       "            -0.0100,      0.0092,      0.0001,     -0.0093,     -0.0102,\n",
       "            -0.0066,     -0.0014,     -0.0038,      0.0165,     -0.0109,\n",
       "            -0.0112,     -0.0201,      0.0032,      0.0042,     -0.0220,\n",
       "             0.0044,     -0.0157,     -0.0110,      0.0040,     -0.0225,\n",
       "            -0.0189,      0.0177,      0.0112,     -0.0059,     -0.0005,\n",
       "             0.0078,      0.0156,     -0.0031,      0.0009,      0.0069,\n",
       "            -0.0110,      0.0214,      0.0161,      0.0016,      0.0263,\n",
       "            -0.0015,      0.0002,     -0.0249,     -0.0074,     -0.0023,\n",
       "            -0.0098,      0.0148,     -0.0061,     -0.0017,      0.0034,\n",
       "            -0.0000,     -0.0144,     -0.0038,     -0.0093,      0.0169,\n",
       "            -0.0054,      0.0100,     -0.0024,     -0.0106,      0.0027,\n",
       "            -0.0066,      0.0030,     -0.0312,     -0.0040,     -0.0118,\n",
       "            -0.0099,      0.0228,      0.0053,     -0.0248,      0.0192,\n",
       "             0.0071,     -0.0056,     -0.0018,      0.0013,     -0.0048,\n",
       "            -0.0014,      0.0051,      0.0031,     -0.0106,     -0.0028,\n",
       "            -0.0170,     -0.0059,      0.0017,     -0.0030,      0.0015,\n",
       "            -0.0108,     -0.0194,     -0.0082,     -0.0053,     -0.0060,\n",
       "             0.0157,      0.0025,      0.0083,     -0.0034,      0.0088,\n",
       "             0.0067,      0.0011,     -0.0063,     -0.0035,     -0.0063,\n",
       "             0.0142,      0.0054,     -0.0105,      0.0159,     -0.0049,\n",
       "             0.0157,     -0.0029,     -0.0019,      0.0062,      0.0063,\n",
       "             0.0034,     -0.0165,     -0.0107,      0.0017,      0.0111,\n",
       "            -0.0050,      0.0012,     -0.0085,      0.0085,     -0.0056,\n",
       "             0.0073,     -0.0035,      0.0032,     -0.0036,     -0.0164,\n",
       "             0.0103,     -0.0120,      0.0073,     -0.0002,     -0.0047,\n",
       "             0.0037,      0.0024,     -0.0174,      0.0114,      0.0096,\n",
       "            -0.0039,     -0.0047,      0.0027,     -0.0015,     -0.0034,\n",
       "             0.0048,      0.0024,     -0.0050,     -0.0024,     -0.0118,\n",
       "             0.0023,      0.0007,      0.0014,      0.0023,     -0.0066,\n",
       "            -0.0160,     -0.0062,     -0.0072,     -0.0038,      0.0138,\n",
       "            -0.0071,      0.0104,      0.0014,      0.0058,      0.0131,\n",
       "            -0.0005,     -0.0036,     -0.0031,     -0.0022,      0.0092,\n",
       "             0.0049,     -0.0007,      0.0116,     -0.0043,      0.0161,\n",
       "            -0.0030,     -0.0048,      0.0001,      0.0032,      0.0045,\n",
       "            -0.0148,     -0.0104,      0.0037,      0.0110,     -0.0052,\n",
       "            -0.0011,     -0.0062,      0.0022,     -0.0034,      0.0065,\n",
       "            -0.0041,     -0.0011,     -0.0045,     -0.0114,      0.0061,\n",
       "            -0.0075,      0.0053,      0.0077,      0.0023,     -0.0014,\n",
       "            -0.0019,     -0.0172,      0.0082,      0.0053,     -0.0096,\n",
       "            -0.0026,      0.0010,     -0.0024,     -0.0090,      0.0001,\n",
       "             0.0026,     -0.0028,     -0.0009,     -0.0051,      0.0023,\n",
       "             0.0033,      0.0014,      0.0041,     -0.0044,     -0.0122,\n",
       "             0.0047,     -0.0025,     -0.0051,      0.0114,     -0.0026,\n",
       "             0.0122,      0.0038,      0.0051,      0.0027,      0.0063,\n",
       "             0.0062,     -0.0022,     -0.0001,      0.0021,      0.0019,\n",
       "            -0.0037,      0.0088,     -0.0038,      0.0065,     -0.0031,\n",
       "            -0.0076,     -0.0033,      0.0019,      0.0011,     -0.0092,\n",
       "            -0.0058,      0.0013,      0.0117,     -0.0085,     -0.0029,\n",
       "            -0.0050,      0.0024,     -0.0048,      0.0041,      0.0027,\n",
       "            -0.0073,     -0.0045,     -0.0080,      0.0005,     -0.0068,\n",
       "            -0.0023,      0.0044,      0.0024,      0.0004,      0.0001,\n",
       "            -0.0135,      0.0086], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_out.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vpy311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
